{
  "1": {
    "inputs": {
      "unet_name": "diffusers_sdxl_inpaint_0.1.safetensors"
    },
    "class_type": "UNETLoader"
  },
  "3": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "5": {
    "inputs": {
      "image": "ComfyUI_00011_v2@0.5x.png",
      "choose file to upload": "image"
    },
    "class_type": "LoadImage"
  },
  "10": {
    "inputs": {
      "samples": [
        "67",
        0
      ],
      "vae": [
        "73",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "13": {
    "inputs": {
      "grow_mask_by": 8,
      "pixels": [
        "5",
        0
      ],
      "vae": [
        "50",
        0
      ],
      "mask": [
        "5",
        1
      ]
    },
    "class_type": "VAEEncodeForInpaint"
  },
  "14": {
    "inputs": {
      "width": [
        "45",
        0
      ],
      "height": [
        "45",
        1
      ],
      "crop_w": 0,
      "crop_h": 0,
      "target_width": [
        "45",
        0
      ],
      "target_height": [
        "45",
        1
      ],
      "text_g": [
        "37",
        0
      ],
      "text_l": "",
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL"
  },
  "37": {
    "inputs": {
      "text": "starwars cantina, desert, 8k Ultra detail landscape, detailed background, "
    },
    "class_type": "Text Multiline"
  },
  "38": {
    "inputs": {
      "filename_prefix": "Refiner",
      "images": [
        "10",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "45": {
    "inputs": {
      "image": [
        "5",
        0
      ]
    },
    "class_type": "ImageGenResolutionFromImage"
  },
  "50": {
    "inputs": {
      "vae_name": "stableDiffusionXl10_v10-inpainting.safetensors"
    },
    "class_type": "VAELoader"
  },
  "59": {
    "inputs": {
      "text": [
        "63",
        0
      ],
      "clip": [
        "3",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "60": {
    "inputs": {
      "text": [
        "37",
        0
      ],
      "clip": [
        "73",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "61": {
    "inputs": {
      "text": [
        "63",
        0
      ],
      "clip": [
        "73",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "63": {
    "inputs": {
      "text": "subject, human, portrait, full shot, bad sky, bad quality background, watermark, text, poor quality, body shot, back turned to camera"
    },
    "class_type": "Text Multiline"
  },
  "66": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 568661044766323,
      "steps": 30,
      "cfg": 7,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "start_at_step": 0,
      "end_at_step": 26,
      "return_with_leftover_noise": "disable",
      "model": [
        "1",
        0
      ],
      "positive": [
        "14",
        0
      ],
      "negative": [
        "59",
        0
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSamplerAdvanced"
  },
  "67": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": 0,
      "steps": 30,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "start_at_step": 26,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "73",
        0
      ],
      "positive": [
        "60",
        0
      ],
      "negative": [
        "61",
        0
      ],
      "latent_image": [
        "66",
        0
      ]
    },
    "class_type": "KSamplerAdvanced"
  },
  "73": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0_0.9vae.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "75": {
    "inputs": {
      "samples": [
        "66",
        0
      ],
      "vae": [
        "50",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "77": {
    "inputs": {
      "filename_prefix": "Inpainting",
      "images": [
        "75",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "78": {
    "inputs": {
      "upscale_model": [
        "79",
        0
      ],
      "image": [
        "10",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel"
  },
  "79": {
    "inputs": {
      "model_name": "RealESRGAN_x2plus.pth"
    },
    "class_type": "Upscale Model Loader"
  },
  "80": {
    "inputs": {
      "filename_prefix": "Refine2xUpscale",
      "images": [
        "78",
        0
      ]
    },
    "class_type": "SaveImage"
  }
}